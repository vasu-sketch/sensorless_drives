{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bce1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffa6e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_6</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_9</th>\n",
       "      <th>current_10</th>\n",
       "      <th>...</th>\n",
       "      <th>current_40</th>\n",
       "      <th>current_41</th>\n",
       "      <th>current_42</th>\n",
       "      <th>current_43</th>\n",
       "      <th>current_44</th>\n",
       "      <th>current_45</th>\n",
       "      <th>current_46</th>\n",
       "      <th>current_47</th>\n",
       "      <th>current_48</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1     current_2  current_3  current_4     current_5  current_6  \\\n",
       "0 -3.014600e-07  8.260300e-06  -0.000012  -0.000002 -1.438600e-06  -0.000021   \n",
       "1  2.913200e-06 -5.247700e-06   0.000003  -0.000006  2.778900e-06  -0.000004   \n",
       "2 -2.951700e-06 -3.184000e-06  -0.000016  -0.000001 -1.575300e-06   0.000017   \n",
       "3 -1.322600e-06  8.820100e-06  -0.000016  -0.000005 -7.282900e-07   0.000004   \n",
       "4 -6.836600e-08  5.666300e-07  -0.000026  -0.000006 -7.940600e-07   0.000013   \n",
       "\n",
       "   current_7  current_8  current_9  current_10  ...  current_40  current_41  \\\n",
       "0   0.031718   0.031710   0.031721   -0.032963  ...    -0.63308      2.9646   \n",
       "1   0.030804   0.030810   0.030806   -0.033520  ...    -0.59314      7.6252   \n",
       "2   0.032877   0.032880   0.032896   -0.029834  ...    -0.63252      2.7784   \n",
       "3   0.029410   0.029401   0.029417   -0.030156  ...    -0.62289      6.5534   \n",
       "4   0.030119   0.030119   0.030145   -0.031393  ...    -0.63010      4.5155   \n",
       "\n",
       "   current_42  current_43  current_44  current_45  current_46  current_47  \\\n",
       "0      8.1198     -1.4961     -1.4961     -1.4961     -1.4996     -1.4996   \n",
       "1      6.1690     -1.4967     -1.4967     -1.4967     -1.5005     -1.5005   \n",
       "2      5.3017     -1.4983     -1.4983     -1.4982     -1.4985     -1.4985   \n",
       "3      6.2606     -1.4963     -1.4963     -1.4963     -1.4975     -1.4975   \n",
       "4      9.5231     -1.4958     -1.4958     -1.4958     -1.4959     -1.4959   \n",
       "\n",
       "   current_48  output  \n",
       "0     -1.4996       1  \n",
       "1     -1.5005       1  \n",
       "2     -1.4985       1  \n",
       "3     -1.4976       1  \n",
       "4     -1.4959       1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Group_9_data_cleaned.csv')\n",
    "data.head(3)\n",
    "# removing a redundant column\n",
    "df = data.drop(['Unnamed: 0'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4fba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58509, 49)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the data \n",
    "# The data has 58509 rows \n",
    "# The data has 49 features \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900013cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_6</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_9</th>\n",
       "      <th>current_10</th>\n",
       "      <th>...</th>\n",
       "      <th>current_40</th>\n",
       "      <th>current_41</th>\n",
       "      <th>current_42</th>\n",
       "      <th>current_43</th>\n",
       "      <th>current_44</th>\n",
       "      <th>current_45</th>\n",
       "      <th>current_46</th>\n",
       "      <th>current_47</th>\n",
       "      <th>current_48</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58509.000000</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.756436e-06</td>\n",
       "      <td>1.111802e-06</td>\n",
       "      <td>-9.722586e-07</td>\n",
       "      <td>1.775487e-06</td>\n",
       "      <td>-7.457535e-07</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.006349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.650427</td>\n",
       "      <td>5.730645</td>\n",
       "      <td>7.702923</td>\n",
       "      <td>-1.500891</td>\n",
       "      <td>-1.500915</td>\n",
       "      <td>-1.500809</td>\n",
       "      <td>-1.497787</td>\n",
       "      <td>-1.497814</td>\n",
       "      <td>-1.497710</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.199783e-05</td>\n",
       "      <td>1.520782e-04</td>\n",
       "      <td>7.956279e-06</td>\n",
       "      <td>3.234750e-05</td>\n",
       "      <td>1.490893e-04</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.033701</td>\n",
       "      <td>0.050735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100670</td>\n",
       "      <td>5.781169</td>\n",
       "      <td>4.347205</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>3.162305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-6.427550e-05</td>\n",
       "      <td>-2.937900e-04</td>\n",
       "      <td>-1.887580e-05</td>\n",
       "      <td>-6.547550e-05</td>\n",
       "      <td>-2.915565e-04</td>\n",
       "      <td>-0.086972</td>\n",
       "      <td>-0.087041</td>\n",
       "      <td>-0.086978</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>-0.596830</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>-1.510950</td>\n",
       "      <td>-1.511200</td>\n",
       "      <td>-1.510700</td>\n",
       "      <td>-1.504700</td>\n",
       "      <td>-1.504550</td>\n",
       "      <td>-1.504450</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.444400e-05</td>\n",
       "      <td>-7.239600e-05</td>\n",
       "      <td>-5.417500e-06</td>\n",
       "      <td>-1.475300e-05</td>\n",
       "      <td>-7.379100e-05</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>-0.019951</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>-0.032144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715470</td>\n",
       "      <td>1.450300</td>\n",
       "      <td>4.436300</td>\n",
       "      <td>-1.503300</td>\n",
       "      <td>-1.503400</td>\n",
       "      <td>-1.503200</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>8.804600e-07</td>\n",
       "      <td>5.137700e-07</td>\n",
       "      <td>-1.059100e-06</td>\n",
       "      <td>7.540200e-07</td>\n",
       "      <td>-1.659300e-07</td>\n",
       "      <td>0.013226</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>-0.015566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661710</td>\n",
       "      <td>3.301300</td>\n",
       "      <td>6.479100</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.877700e-05</td>\n",
       "      <td>7.520000e-05</td>\n",
       "      <td>3.554700e-06</td>\n",
       "      <td>1.906200e-05</td>\n",
       "      <td>7.138600e-05</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573980</td>\n",
       "      <td>8.288500</td>\n",
       "      <td>9.857500</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>-1.496300</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>6.860850e-05</td>\n",
       "      <td>2.965940e-04</td>\n",
       "      <td>1.701300e-05</td>\n",
       "      <td>6.978450e-05</td>\n",
       "      <td>2.891515e-04</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.069130</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>0.099751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361745</td>\n",
       "      <td>18.545800</td>\n",
       "      <td>17.989300</td>\n",
       "      <td>-1.490550</td>\n",
       "      <td>-1.490400</td>\n",
       "      <td>-1.490700</td>\n",
       "      <td>-1.491100</td>\n",
       "      <td>-1.491350</td>\n",
       "      <td>-1.491250</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          current_1     current_2     current_3     current_4     current_5  \\\n",
       "count  58509.000000  5.850900e+04  5.850900e+04  5.850900e+04  5.850900e+04   \n",
       "mean      -0.000003  1.756436e-06  1.111802e-06 -9.722586e-07  1.775487e-06   \n",
       "std        0.000008  3.199783e-05  1.520782e-04  7.956279e-06  3.234750e-05   \n",
       "min       -0.000021 -6.427550e-05 -2.937900e-04 -1.887580e-05 -6.547550e-05   \n",
       "25%       -0.000007 -1.444400e-05 -7.239600e-05 -5.417500e-06 -1.475300e-05   \n",
       "50%       -0.000003  8.804600e-07  5.137700e-07 -1.059100e-06  7.540200e-07   \n",
       "75%        0.000002  1.877700e-05  7.520000e-05  3.554700e-06  1.906200e-05   \n",
       "max        0.000015  6.860850e-05  2.965940e-04  1.701300e-05  6.978450e-05   \n",
       "\n",
       "          current_6     current_7     current_8     current_9    current_10  \\\n",
       "count  5.850900e+04  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean  -7.457535e-07      0.002854      0.002849      0.002849     -0.006349   \n",
       "std    1.490893e-04      0.033692      0.033700      0.033701      0.050735   \n",
       "min   -2.915565e-04     -0.086972     -0.087041     -0.086978     -0.111281   \n",
       "25%   -7.379100e-05     -0.019927     -0.019951     -0.019925     -0.032144   \n",
       "50%   -1.659300e-07      0.013226      0.013230      0.013247     -0.015566   \n",
       "75%    7.138600e-05      0.024770      0.024776      0.024777      0.020614   \n",
       "max    2.891515e-04      0.069125      0.069130      0.069131      0.099751   \n",
       "\n",
       "       ...    current_40    current_41    current_42    current_43  \\\n",
       "count  ...  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean   ...     -0.650427      5.730645      7.702923     -1.500891   \n",
       "std    ...      0.100670      5.781169      4.347205      0.003629   \n",
       "min    ...     -0.902350     -0.596830      0.320660     -1.510950   \n",
       "25%    ...     -0.715470      1.450300      4.436300     -1.503300   \n",
       "50%    ...     -0.661710      3.301300      6.479100     -1.500300   \n",
       "75%    ...     -0.573980      8.288500      9.857500     -1.498200   \n",
       "max    ...     -0.361745     18.545800     17.989300     -1.490550   \n",
       "\n",
       "         current_44    current_45    current_46    current_47    current_48  \\\n",
       "count  58509.000000  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean      -1.500915     -1.500809     -1.497787     -1.497814     -1.497710   \n",
       "std        0.003640      0.003600      0.003002      0.002984      0.002988   \n",
       "min       -1.511200     -1.510700     -1.504700     -1.504550     -1.504450   \n",
       "25%       -1.503400     -1.503200     -1.499600     -1.499600     -1.499500   \n",
       "50%       -1.500300     -1.500300     -1.498100     -1.498100     -1.498000   \n",
       "75%       -1.498200     -1.498200     -1.496200     -1.496300     -1.496200   \n",
       "max       -1.490400     -1.490700     -1.491100     -1.491350     -1.491250   \n",
       "\n",
       "             output  \n",
       "count  58509.000000  \n",
       "mean       6.000000  \n",
       "std        3.162305  \n",
       "min        1.000000  \n",
       "25%        3.000000  \n",
       "50%        6.000000  \n",
       "75%        9.000000  \n",
       "max       11.000000  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of the data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48c8dba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 11 different classes in the output data \n",
    "# which are from 1 to 11 classes \n",
    "df['output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66117637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5319\n",
       "2     5319\n",
       "3     5319\n",
       "4     5319\n",
       "5     5319\n",
       "6     5319\n",
       "7     5319\n",
       "8     5319\n",
       "9     5319\n",
       "10    5319\n",
       "11    5319\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the number of each output class labels \n",
    "# It is a blanced multi class dataset with each class is having equal number of output labels \n",
    "df['output'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e19a7",
   "metadata": {},
   "source": [
    "## classification with svm Linear kernel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b8842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing input and output labels\n",
    "X = df.drop(['output'],axis=1)\n",
    "y = df['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066267a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5730026  0.54585804 0.47811763 ... 0.375      0.375      0.36742424]\n",
      " [0.66228185 0.44420547 0.50328617 ... 0.30882353 0.30681818 0.29924242]\n",
      " [0.49939872 0.45973556 0.47065977 ... 0.45588235 0.45833333 0.45075758]\n",
      " ...\n",
      " [0.41869175 0.62362286 0.32534757 ... 1.         1.         1.        ]\n",
      " [0.45803432 0.73932528 0.         ... 0.84558824 0.85984848 0.85984848]\n",
      " [0.33549635 0.87696412 0.62036912 ... 0.75       0.75378788 0.76893939]]\n"
     ]
    }
   ],
   "source": [
    "# importing Min Max scalar for the data transformation\n",
    "# Scaling is very important in the case of linear regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "print(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c39a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset into train,test and validation sets\n",
    "X_train, X_rem, y_train, y_rem  = train_test_split(scaled_X, y, train_size = 0.5, random_state = 100)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size = 0.5, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "299916e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The input training  data shape is (29254, 48)\n",
      " The  output training data shape is (29254,)\n",
      " The input validation  data shape is (14627, 48)\n",
      " The  output validation data shape is (14627,)\n",
      " The input testing  data shape is (14627, 48)\n",
      " The  output testing data shape is (14627,)\n"
     ]
    }
   ],
   "source": [
    "# The shape of training dataset\n",
    "print(f\" The input training  data shape is {X_train.shape}\")\n",
    "print(f\" The  output training data shape is {y_train.shape}\")\n",
    "print(f\" The input validation  data shape is {X_valid.shape}\")\n",
    "print(f\" The  output validation data shape is {y_valid.shape}\")\n",
    "# The shape of the test dataset \n",
    "print(f\" The input testing  data shape is {X_valid.shape}\")\n",
    "print(f\" The  output testing data shape is {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6e6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "538ff264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing a random model\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel ='linear')\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fce1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = svc.predict(X_train)\n",
    "y_valid_pred = svc.predict(X_valid)\n",
    "y_test_pred  = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12c2ef",
   "metadata": {},
   "source": [
    "#### accuracies of the random model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ebe29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9311205305257401\n",
      " The validation data accuracy for the best model is 0.929035345593765\n",
      " The testing data accuracy for the best model is 0.9284249384741592\n"
     ]
    }
   ],
   "source": [
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2225d7",
   "metadata": {},
   "source": [
    "## Hyper parameter validation  using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2acd0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc3528c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.895 total time=   5.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.883 total time=   5.2s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.883 total time=   4.7s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.884 total time=   4.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.881 total time=   4.3s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.895 total time=   4.2s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.883 total time=   4.3s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.883 total time=   4.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.884 total time=   4.3s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.881 total time=   4.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.895 total time=   3.9s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.883 total time=   4.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.883 total time=   3.9s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.884 total time=   3.9s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.881 total time=   3.9s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.895 total time=   4.5s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.883 total time=   3.7s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.883 total time=   3.6s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.884 total time=   3.6s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.881 total time=   3.6s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.932 total time=   2.1s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.919 total time=   2.1s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.927 total time=   2.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.919 total time=   2.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.917 total time=   2.1s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.932 total time=   2.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.919 total time=   2.1s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.927 total time=   2.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.919 total time=   2.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.917 total time=   2.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.932 total time=   2.1s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.919 total time=   2.1s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.927 total time=   2.1s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.919 total time=   2.1s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.917 total time=   2.1s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.932 total time=   2.1s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.919 total time=   2.1s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.927 total time=   2.1s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.919 total time=   2.1s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.917 total time=   2.2s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.936 total time=   2.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.923 total time=   1.9s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.929 total time=   1.9s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.926 total time=   1.9s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.926 total time=   1.8s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.936 total time=   2.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.923 total time=   1.9s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.929 total time=   2.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.926 total time=   1.9s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.926 total time=   1.9s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.936 total time=   1.9s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.923 total time=   1.9s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.929 total time=   2.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.926 total time=   1.9s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.926 total time=   1.9s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.936 total time=   1.9s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.923 total time=   1.9s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.929 total time=   1.9s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.926 total time=   1.9s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.926 total time=   1.9s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.937 total time=   4.3s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.927 total time=   4.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.935 total time=   3.8s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.930 total time=   3.8s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.926 total time=   3.6s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.937 total time=   4.3s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.927 total time=   4.2s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.935 total time=   4.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.930 total time=   3.6s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.926 total time=   3.6s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.937 total time=   4.5s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.927 total time=   4.7s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.935 total time=   4.5s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.930 total time=   4.4s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.926 total time=   3.9s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.937 total time=   4.6s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.927 total time=   4.3s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.935 total time=   4.2s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.930 total time=   4.0s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.926 total time=   4.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['linear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(kernel ='linear')\n",
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['linear']}\n",
    "grid = GridSearchCV(svc, param_grid, refit = True, verbose = 3)\n",
    "grid.fit(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d0ffb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "880c8d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best svm linear model\n",
    "best_svc = svm.SVC(kernel ='linear',C=100,gamma=1,probability=True)\n",
    "best_svc.fit(X_train,y_train)\n",
    "file_name = 'svm_linear.sav'\n",
    "pickle.dump(best_svc,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111b9da",
   "metadata": {},
   "source": [
    "### accuracies of the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4852753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9402474875230737\n",
      " The validation data accuracy for the best model is 0.9345730498393382\n",
      " The testing data accuracy for the best model is 0.9365600218758545\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = best_svc.predict(X_train)\n",
    "y_valid_pred = best_svc.predict(X_valid)\n",
    "y_test_pred  = best_svc.predict(X_test)\n",
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495c035",
   "metadata": {},
   "source": [
    "### confusion matrix for train,test and validation datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf66324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2604    0    0    0    0   80    0    0    0    0    0]\n",
      " [   1 2355    0    0    0    0    0    0    4  203    0]\n",
      " [   0    0 2682    9   48    0    0    0    0    0    0]\n",
      " [   0    0   19 2656   13    0    0    0    0    0    0]\n",
      " [   0    0   46   27 2323    0    0  320    0    0    0]\n",
      " [  94    0    3    0    0 2329    0    0  182    0    0]\n",
      " [   0    0    0    0    0    0 2686    0    0    0    0]\n",
      " [   0    1    0   14  209    0    0 2432    0    0    0]\n",
      " [  26   11    0    0    0  184    0    0 2477    1    0]\n",
      " [   0  253    0    0    0    0    0    0    0 2364    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 2598]]\n"
     ]
    }
   ],
   "source": [
    "### Training Data\n",
    "print(confusion_matrix(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94bc7ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1285    0    0    0    0   46    0    0    1    0    0]\n",
      " [   0 1285    1    0    0    0    0    0    0  103    0]\n",
      " [   0    0 1264    3   21    0    0    0    2    0    0]\n",
      " [   0    0   12 1316    8    0    0    0    0    0    0]\n",
      " [   0    0   31   22 1105    0    0  144    0    0    0]\n",
      " [  61    0    4    0    0 1172    0    0  103    0    0]\n",
      " [   0    0    0    1    0    0 1304    0    0    0    0]\n",
      " [   0    0    0    6   95    0    0 1218    0    0    0]\n",
      " [   8    4    1    0    0  126    0    0 1185    1    0]\n",
      " [   0  153    0    0    0    0    0    0    0 1190    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1346]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for validation data\n",
    "print(confusion_matrix(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4fe298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1272    0    0    0    0   31    0    0    0    0    0]\n",
      " [   0 1265    0    0    0    0    0    0    1  100    1]\n",
      " [   0    0 1261    6   22    0    0    0    1    0    0]\n",
      " [   0    0    8 1277    9    0    1    0    0    0    0]\n",
      " [   0    0   22   24 1084    0    0  171    0    0    0]\n",
      " [  49    0    5    0    0 1211    0    0  106    0    0]\n",
      " [   0    0    0    0    0    0 1328    0    0    0    0]\n",
      " [   0    0    0    3  106    0    0 1235    0    0    0]\n",
      " [   8    5    1    0    1   92    0    0 1188    0    0]\n",
      " [   0  155    0    0    0    0    0    0    0 1204    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1375]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for testing data svm linear kernel\n",
    "print(confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c051f",
   "metadata": {},
   "source": [
    "### classification report for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07ee472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.97      0.96      2684\n",
      "           2       0.90      0.92      0.91      2563\n",
      "           3       0.98      0.98      0.98      2739\n",
      "           4       0.98      0.99      0.98      2688\n",
      "           5       0.90      0.86      0.88      2716\n",
      "           6       0.90      0.89      0.90      2608\n",
      "           7       1.00      1.00      1.00      2686\n",
      "           8       0.88      0.92      0.90      2656\n",
      "           9       0.93      0.92      0.92      2699\n",
      "          10       0.92      0.90      0.91      2617\n",
      "          11       1.00      1.00      1.00      2598\n",
      "\n",
      "    accuracy                           0.94     29254\n",
      "   macro avg       0.94      0.94      0.94     29254\n",
      "weighted avg       0.94      0.94      0.94     29254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the training data\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1755b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.98      0.97      1303\n",
      "           2       0.89      0.93      0.91      1367\n",
      "           3       0.97      0.98      0.97      1290\n",
      "           4       0.97      0.99      0.98      1295\n",
      "           5       0.89      0.83      0.86      1301\n",
      "           6       0.91      0.88      0.90      1371\n",
      "           7       1.00      1.00      1.00      1328\n",
      "           8       0.88      0.92      0.90      1344\n",
      "           9       0.92      0.92      0.92      1295\n",
      "          10       0.92      0.89      0.90      1359\n",
      "          11       1.00      1.00      1.00      1375\n",
      "\n",
      "    accuracy                           0.94     14628\n",
      "   macro avg       0.94      0.94      0.94     14628\n",
      "weighted avg       0.94      0.94      0.94     14628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for the testing data\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab9e9c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.96      0.96      1332\n",
      "           2       0.89      0.93      0.91      1389\n",
      "           3       0.96      0.98      0.97      1290\n",
      "           4       0.98      0.99      0.98      1336\n",
      "           5       0.90      0.85      0.87      1302\n",
      "           6       0.87      0.87      0.87      1340\n",
      "           7       1.00      1.00      1.00      1305\n",
      "           8       0.89      0.92      0.91      1319\n",
      "           9       0.92      0.89      0.91      1325\n",
      "          10       0.92      0.89      0.90      1343\n",
      "          11       1.00      1.00      1.00      1346\n",
      "\n",
      "    accuracy                           0.93     14627\n",
      "   macro avg       0.93      0.93      0.93     14627\n",
      "weighted avg       0.93      0.93      0.93     14627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for the validation data\n",
    "print(classification_report(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f1f65",
   "metadata": {},
   "source": [
    "### ROC AUC score for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a74ef15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The roc_auc score for the training data is 0.9973207305099111\n",
      " The roc_auc score for the validation data is 0.9969811902439999\n",
      " The roc_auc score for the testing data is 0.9967536766122579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# roc auc score for training data\n",
    "y_train_prob = best_svc.predict_proba(X_train)\n",
    "print(f\" The roc_auc score for the training data is {roc_auc_score(y_train,y_train_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the validation data\n",
    "y_valid_prob = best_svc.predict_proba(X_valid)\n",
    "print(f\" The roc_auc score for the validation data is {roc_auc_score(y_valid,y_valid_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the testing data\n",
    "y_test_prob = best_svc.predict_proba(X_test)\n",
    "print(f\" The roc_auc score for the testing data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67362241",
   "metadata": {},
   "source": [
    "### Recall score of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca8b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The recall score for the training data is 0.9401255760050685\n",
      " The recall score for the validation data is 0.9346466286455641\n",
      " The recall score for the testing data is 0.9367212302821362\n"
     ]
    }
   ],
   "source": [
    "# recall score for training data\n",
    "print(f\" The recall score for the training data is {recall_score(y_train,y_train_pred,average= 'macro')}\")\n",
    "# recall score for validation data\n",
    "print(f\" The recall score for the validation data is {recall_score(y_valid,y_valid_pred,average= 'macro')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the testing data is {recall_score(y_test,y_test_pred,average= 'macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91716411",
   "metadata": {},
   "source": [
    "### F1 score of the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd8a23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The f-1 score for the training data is 0.9401265071966416\n",
      " The f-1 score for the validation data is 0.9343657700706681\n",
      " The f-1 score for the testing data is 0.9363181793454444\n"
     ]
    }
   ],
   "source": [
    "# F-1 score for training data\n",
    "print(f\" The f-1 score for the training data is {f1_score(y_train,y_train_pred,average= 'weighted')}\")\n",
    "# F-1 score for validation data\n",
    "print(f\" The f-1 score for the validation data is {f1_score(y_valid,y_valid_pred,average= 'weighted')}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the testing data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bd7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b891d79",
   "metadata": {},
   "source": [
    "# classification using Non Linear svm kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f23387",
   "metadata": {},
   "source": [
    "### Finding best model using Hyper parameter validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ed2ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c348656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.775 total time=  13.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.766 total time=  13.9s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.774 total time=  16.7s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.780 total time=  15.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.786 total time=  13.7s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.975 total time=   1.8s\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.975 total time=   1.8s\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.971 total time=   2.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.975 total time=   2.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.970 total time=   2.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.095 total time=  16.7s\n",
      "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.1s\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.2s\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.2s\n",
      "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.746 total time=   5.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.737 total time=   5.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.732 total time=   5.5s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.747 total time=   5.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.740 total time=   5.3s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.830 total time=   1.9s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.816 total time=   2.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.802 total time=   1.9s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.820 total time=   2.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.805 total time=   2.1s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.377 total time=   8.1s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.370 total time=   8.4s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.374 total time=   8.2s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.374 total time=   8.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.369 total time=   8.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.462 total time=   8.3s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.454 total time=   8.3s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.459 total time=   8.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.458 total time=   8.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.458 total time=   8.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.095 total time=   6.3s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.095 total time=   6.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.095 total time=   6.1s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.095 total time=   7.8s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.095 total time=   8.4s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.335 total time=   7.2s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.338 total time=   6.9s\n",
      "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.344 total time=   7.6s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.342 total time=   7.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.336 total time=   6.7s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.095 total time=   9.4s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.095 total time=  10.5s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.095 total time=   9.7s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.095 total time=   9.7s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.095 total time=   9.5s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.095 total time=   6.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.095 total time=   6.2s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.095 total time=   6.2s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.095 total time=   7.1s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.095 total time=   7.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.095 total time=   7.7s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.095 total time=   8.3s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.095 total time=  10.2s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.095 total time=  14.4s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.095 total time=  10.8s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.953 total time=   6.8s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.942 total time=   8.4s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.947 total time=   5.2s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.955 total time=   4.6s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.946 total time=   5.3s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.971 total time=   1.0s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.969 total time=   1.0s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.968 total time=   0.9s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.969 total time=   1.0s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.967 total time=   0.9s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.9s\n",
      "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.095 total time=  11.8s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.095 total time=  12.7s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.095 total time=  13.6s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.095 total time=  11.7s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.948 total time=   3.1s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.938 total time=   3.9s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.933 total time=   3.9s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.942 total time=   3.3s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.939 total time=   2.7s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.961 total time=   1.1s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.954 total time=   1.7s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.956 total time=   1.9s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.959 total time=   2.2s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.959 total time=   1.5s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.268 total time=   5.9s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.269 total time=   5.2s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.273 total time=   5.2s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.274 total time=   5.2s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.268 total time=   5.5s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.762 total time=   5.4s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.746 total time=   7.5s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.745 total time=   7.1s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.758 total time=   6.2s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.747 total time=   6.9s\n",
      "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.118 total time=   8.8s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.116 total time=   7.7s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.109 total time=   6.6s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.115 total time=   6.2s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.116 total time=   8.8s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.708 total time=   4.4s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.698 total time=   5.6s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.692 total time=   4.1s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.706 total time=   4.1s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.704 total time=   3.9s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.476 total time=   8.5s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.468 total time=   8.7s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.471 total time=   8.2s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.474 total time=   8.6s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.471 total time=   8.6s\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.095 total time=   6.3s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.095 total time=   6.6s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.095 total time=   9.8s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.095 total time=   7.1s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.095 total time=   7.1s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.336 total time=   7.7s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.338 total time=   7.7s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.346 total time=   8.5s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.343 total time=   8.7s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.337 total time=   7.9s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.968 total time=   5.3s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.958 total time=   4.9s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.966 total time=   5.3s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.971 total time=   5.2s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.961 total time=   5.2s\n",
      "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.969 total time=   1.0s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.968 total time=   0.9s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.966 total time=   1.0s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.968 total time=   1.1s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.968 total time=   1.1s\n",
      "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.095 total time=  12.0s\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.095 total time=   9.7s\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.095 total time=  11.2s\n",
      "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.5s\n",
      "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.3s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.979 total time=   1.9s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.975 total time=   1.9s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.972 total time=   1.6s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.976 total time=   1.7s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.972 total time=   1.5s\n",
      "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.977 total time=   0.6s\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.974 total time=   0.6s\n",
      "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.973 total time=   0.8s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.974 total time=   0.8s\n",
      "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.974 total time=   0.6s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.225 total time=   3.8s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.238 total time=   5.3s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.236 total time=   3.9s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.229 total time=   3.8s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.247 total time=   4.2s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.925 total time=   2.5s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.912 total time=   2.5s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.915 total time=   2.5s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.917 total time=   2.5s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.914 total time=   2.7s\n",
      "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.622 total time=   4.2s\n",
      "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.611 total time=   4.4s\n",
      "[CV 3/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.617 total time=   4.2s\n",
      "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.626 total time=   4.4s\n",
      "[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.620 total time=   4.4s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.892 total time=   2.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.881 total time=   2.2s\n",
      "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.881 total time=   1.9s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.884 total time=   2.0s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.879 total time=   3.1s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.762 total time=   8.1s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.746 total time=   6.3s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.747 total time=   4.8s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.757 total time=   5.1s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.747 total time=   4.8s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.095 total time=   6.3s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.095 total time=   6.6s\n",
      "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.095 total time=   6.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.095 total time=   6.7s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.095 total time=   6.6s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.709 total time=   4.2s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.700 total time=   4.0s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.693 total time=   4.2s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.706 total time=   4.3s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.705 total time=   4.3s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.968 total time=   5.6s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.958 total time=   5.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.966 total time=   4.8s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.971 total time=   6.4s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.961 total time=   4.9s\n",
      "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.969 total time=   1.0s\n",
      "[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=0.968 total time=   0.9s\n",
      "[CV 3/5] END .......C=100, gamma=1, kernel=poly;, score=0.966 total time=   1.0s\n",
      "[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=0.968 total time=   1.1s\n",
      "[CV 5/5] END .......C=100, gamma=1, kernel=poly;, score=0.968 total time=   1.0s\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.8s\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.9s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.095 total time=  10.7s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.095 total time=  12.6s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.095 total time=  11.6s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.983 total time=   1.8s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.980 total time=   1.7s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.978 total time=   1.8s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.977 total time=   1.6s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.978 total time=   1.7s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.975 total time=   0.9s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.975 total time=   0.9s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.971 total time=   1.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.975 total time=   0.9s\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.970 total time=   1.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.219 total time=   4.5s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.234 total time=   4.9s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.231 total time=   4.2s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.225 total time=   4.4s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.241 total time=   3.8s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.964 total time=   1.6s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.959 total time=   1.3s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.958 total time=   1.4s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.959 total time=   1.4s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.958 total time=   1.4s\n",
      "[CV 1/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.830 total time=   2.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.816 total time=   2.2s\n",
      "[CV 3/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.802 total time=   2.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.820 total time=   2.2s\n",
      "[CV 5/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.805 total time=   2.0s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.917 total time=   1.1s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.905 total time=   1.3s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.915 total time=   1.5s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.907 total time=   1.0s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.903 total time=   1.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.913 total time=   2.8s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.902 total time=   2.6s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.909 total time=   2.6s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.907 total time=   2.6s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.904 total time=   2.7s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.095 total time=   6.1s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.095 total time=   6.2s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.095 total time=   6.7s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.095 total time=   6.5s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.095 total time=   6.5s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.895 total time=   2.1s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.883 total time=   2.0s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.883 total time=   2.1s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.884 total time=   1.9s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.881 total time=   2.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC()\n",
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf','poly','sigmoid']}\n",
    "grid = GridSearchCV(svc, param_grid, refit = True, verbose = 3)\n",
    "grid.fit(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92c52755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4172ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best svm non_linear model \n",
    "best_non_linear = svm.SVC(C= 100, gamma= 0.1, kernel= 'rbf',probability=True)\n",
    "best_non_linear.fit(X_train,y_train)\n",
    "file_name = 'svm_nonlinear.sav'\n",
    "pickle.dump(best_non_linear,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55454cbc",
   "metadata": {},
   "source": [
    "#### accuracies of the best model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e1960ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9960347302932933\n",
      " The validation data accuracy for the best model is 0.9860531893074451\n",
      " The testing data accuracy for the best model is 0.9849603500136724\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = best_non_linear.predict(X_train)\n",
    "y_valid_pred = best_non_linear.predict(X_valid)\n",
    "y_test_pred  = best_non_linear.predict(X_test)\n",
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d59114d",
   "metadata": {},
   "source": [
    "### confusion matrix for the non linear svm best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b07c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2680    0    0    0    0    4    0    0    0    0    0]\n",
      " [   0 2539    0    0    0    0    0    0    0   24    0]\n",
      " [   0    0 2739    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 2688    0    0    0    0    0    0    0]\n",
      " [   0    0    1    0 2702    0    0   13    0    0    0]\n",
      " [   2    0    0    0    0 2604    0    0    2    0    0]\n",
      " [   0    0    0    0    0    0 2686    0    0    0    0]\n",
      " [   0    0    0    2   11    0    0 2643    0    0    0]\n",
      " [   0    0    0    0    0    3    0    0 2696    0    0]\n",
      " [   0   54    0    0    0    0    0    0    0 2563    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 2598]]\n"
     ]
    }
   ],
   "source": [
    "### Training Data\n",
    "print(confusion_matrix(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2e756b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1321    0    0    0    0   11    0    0    0    0    0]\n",
      " [   0 1355    1    0    0    0    0    0    0   33    0]\n",
      " [   0    0 1288    0    2    0    0    0    0    0    0]\n",
      " [   0    0    0 1336    0    0    0    0    0    0    0]\n",
      " [   0    0    2    0 1275    0    0   25    0    0    0]\n",
      " [   6    0    0    0    0 1320    0    0   14    0    0]\n",
      " [   0    0    0    1    0    0 1304    0    0    0    0]\n",
      " [   0    0    0    5   22    0    0 1292    0    0    0]\n",
      " [   1    0    0    0    0    5    0    0 1318    1    0]\n",
      " [   0   75    0    0    0    0    0    0    0 1268    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1346]]\n"
     ]
    }
   ],
   "source": [
    "### validation Data\n",
    "print(confusion_matrix(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88607bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1298    0    0    0    0    5    0    0    0    0    0]\n",
      " [   0 1323    0    0    0    0    0    0    0   43    1]\n",
      " [   0    0 1285    0    5    0    0    0    0    0    0]\n",
      " [   0    0    0 1294    0    0    1    0    0    0    0]\n",
      " [   0    0    3    0 1266    0    0   32    0    0    0]\n",
      " [  12    0    0    0    1 1346    0    0   12    0    0]\n",
      " [   0    0    0    0    0    0 1328    0    0    0    0]\n",
      " [   0    0    0    4   23    0    0 1317    0    0    0]\n",
      " [   2    0    0    0    0    8    0    0 1284    1    0]\n",
      " [   0   67    0    0    0    0    0    0    0 1292    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1375]]\n"
     ]
    }
   ],
   "source": [
    "### Test  Data for svm non linear model\n",
    "print(confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6b641",
   "metadata": {},
   "source": [
    "### classification report for the svm non linear best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b72632f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      2684\n",
      "           2       0.98      0.99      0.98      2563\n",
      "           3       1.00      1.00      1.00      2739\n",
      "           4       1.00      1.00      1.00      2688\n",
      "           5       1.00      0.99      1.00      2716\n",
      "           6       1.00      1.00      1.00      2608\n",
      "           7       1.00      1.00      1.00      2686\n",
      "           8       1.00      1.00      1.00      2656\n",
      "           9       1.00      1.00      1.00      2699\n",
      "          10       0.99      0.98      0.99      2617\n",
      "          11       1.00      1.00      1.00      2598\n",
      "\n",
      "    accuracy                           1.00     29254\n",
      "   macro avg       1.00      1.00      1.00     29254\n",
      "weighted avg       1.00      1.00      1.00     29254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the training data\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9acc2922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99      1332\n",
      "           2       0.95      0.98      0.96      1389\n",
      "           3       1.00      1.00      1.00      1290\n",
      "           4       1.00      1.00      1.00      1336\n",
      "           5       0.98      0.98      0.98      1302\n",
      "           6       0.99      0.99      0.99      1340\n",
      "           7       1.00      1.00      1.00      1305\n",
      "           8       0.98      0.98      0.98      1319\n",
      "           9       0.99      0.99      0.99      1325\n",
      "          10       0.97      0.94      0.96      1343\n",
      "          11       1.00      1.00      1.00      1346\n",
      "\n",
      "    accuracy                           0.99     14627\n",
      "   macro avg       0.99      0.99      0.99     14627\n",
      "weighted avg       0.99      0.99      0.99     14627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the validation data\n",
    "print(classification_report(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15e25294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      0.99      1303\n",
      "           2       0.95      0.97      0.96      1367\n",
      "           3       1.00      1.00      1.00      1290\n",
      "           4       1.00      1.00      1.00      1295\n",
      "           5       0.98      0.97      0.98      1301\n",
      "           6       0.99      0.98      0.99      1371\n",
      "           7       1.00      1.00      1.00      1328\n",
      "           8       0.98      0.98      0.98      1344\n",
      "           9       0.99      0.99      0.99      1295\n",
      "          10       0.97      0.95      0.96      1359\n",
      "          11       1.00      1.00      1.00      1375\n",
      "\n",
      "    accuracy                           0.98     14628\n",
      "   macro avg       0.99      0.99      0.99     14628\n",
      "weighted avg       0.98      0.98      0.98     14628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the test data\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0b27d",
   "metadata": {},
   "source": [
    "### Roc_auc scores for the svm non linear best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2068e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The roc_auc score for the training data is 0.9999711530464098\n",
      " The roc_auc score for the validation data is 0.9997791927074581\n",
      " The roc_auc score for the testing data is 0.9997332562569385\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# roc auc score for training data\n",
    "y_train_prob = best_non_linear.predict_proba(X_train)\n",
    "print(f\" The roc_auc score for the training data is {roc_auc_score(y_train,y_train_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the validation data\n",
    "y_valid_prob = best_non_linear.predict_proba(X_valid)\n",
    "print(f\" The roc_auc score for the validation data is {roc_auc_score(y_valid,y_valid_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the testing data\n",
    "y_test_prob = best_non_linear.predict_proba(X_test)\n",
    "print(f\" The roc_auc score for the testing data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc63ef",
   "metadata": {},
   "source": [
    "### Recall score for the svm non linear best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "557e6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The recall score for the training data is 0.9959833512542489\n",
      " The recall score for the validation data is 0.9861532848856643\n",
      " The recall score for the testing data is 0.9851186874234373\n"
     ]
    }
   ],
   "source": [
    "# recall score for training data\n",
    "print(f\" The recall score for the training data is {recall_score(y_train,y_train_pred,average= 'macro')}\")\n",
    "# recall score for validation data\n",
    "print(f\" The recall score for the validation data is {recall_score(y_valid,y_valid_pred,average= 'macro')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the testing data is {recall_score(y_test,y_test_pred,average= 'macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a1c14",
   "metadata": {},
   "source": [
    "### f1-score for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93be7064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The f-1 score for the training data is 0.996034635570661\n",
      " The f-1 score for the validation data is 0.9860459040373616\n",
      " The f-1 score for the testing data is 0.9849551502008304\n"
     ]
    }
   ],
   "source": [
    "# F-1 score for training data\n",
    "print(f\" The f-1 score for the training data is {f1_score(y_train,y_train_pred,average= 'weighted')}\")\n",
    "# F-1 score for validation data\n",
    "print(f\" The f-1 score for the validation data is {f1_score(y_valid,y_valid_pred,average= 'weighted')}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the testing data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd05740",
   "metadata": {},
   "source": [
    "# classification  using Deep  Learning Model, Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17562e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the deep learning model\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d25afcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking random model\n",
    "mlp = MLPClassifier()\n",
    "#fitting random model with training data\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec78335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding accuracy for the random model\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_valid_pred = mlp.predict(X_valid)\n",
    "y_test_pred  = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c9084a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9934026116086689\n",
      " The validation data accuracy for the best model is 0.9867368564982566\n",
      " The testing data accuracy for the best model is 0.9859174186491659\n"
     ]
    }
   ],
   "source": [
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2d155",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c99bb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=MLPClassifier(),\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;logistic&#x27;],\n",
       "                                        &#x27;alpha&#x27;: [0.0001, 0.001, 0.01],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,), (200,),\n",
       "                                                               (500,),\n",
       "                                                               (1000,)],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;adam&#x27;, &#x27;sgd&#x27;]},\n",
       "                   random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=MLPClassifier(),\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;logistic&#x27;],\n",
       "                                        &#x27;alpha&#x27;: [0.0001, 0.001, 0.01],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,), (200,),\n",
       "                                                               (500,),\n",
       "                                                               (1000,)],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;adam&#x27;, &#x27;sgd&#x27;]},\n",
       "                   random_state=0)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=MLPClassifier(),\n",
       "                   param_distributions={'activation': ['relu', 'logistic'],\n",
       "                                        'alpha': [0.0001, 0.001, 0.01],\n",
       "                                        'hidden_layer_sizes': [(100,), (200,),\n",
       "                                                               (500,),\n",
       "                                                               (1000,)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'adaptive'],\n",
       "                                        'solver': ['adam', 'sgd']},\n",
       "                   random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "mlp = MLPClassifier()\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (200,), (500,), (1000,)],\n",
    "    'activation': ['relu', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "\n",
    "clf = RandomizedSearchCV(mlp, param_grid, random_state=0)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e033ef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (500,), 'alpha': 0.001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(f'Best hyperparameters: {clf.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0336cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# best model \n",
    "best_model_mlp =  MLPClassifier(solver= 'adam', learning_rate= 'adaptive', hidden_layer_sizes= (500,), alpha= 0.001, activation= 'relu')\n",
    "best_model_mlp.fit(X_train,y_train)\n",
    "file_name = 'mlp.sav'\n",
    "pickle.dump(best_model_mlp,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ebb30",
   "metadata": {},
   "source": [
    "#### accuracies of the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84ed55a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.9996239830450536\n",
      " The validation data accuracy for the best model is 0.9924796609010733\n",
      " The testing data accuracy for the best model is 0.9924801750068362\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = best_model_mlp.predict(X_train)\n",
    "y_valid_pred = best_model_mlp.predict(X_valid)\n",
    "y_test_pred  = best_model_mlp.predict(X_test)\n",
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8acaba",
   "metadata": {},
   "source": [
    "### confusion matrix for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e475d43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2680    0    0    0    0    4    0    0    0    0    0]\n",
      " [   0 2562    0    0    0    0    0    0    0    1    0]\n",
      " [   0    0 2739    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 2688    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0 2715    0    0    1    0    0    0]\n",
      " [   0    0    0    0    0 2607    0    0    1    0    0]\n",
      " [   0    0    0    0    0    0 2686    0    0    0    0]\n",
      " [   0    0    0    0    2    0    0 2654    0    0    0]\n",
      " [   0    0    0    0    0    1    0    0 2697    1    0]\n",
      " [   0    0    0    0    0    0    0    0    0 2617    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 2598]]\n"
     ]
    }
   ],
   "source": [
    "### Training Data\n",
    "print(confusion_matrix(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae863f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1319    0    0    0    0   13    0    0    0    0    0]\n",
      " [   0 1373    0    0    0    0    0    0    0   16    0]\n",
      " [   0    0 1285    0    4    0    0    0    1    0    0]\n",
      " [   0    0    0 1336    0    0    0    0    0    0    0]\n",
      " [   0    0    2    1 1288    0    0   11    0    0    0]\n",
      " [   2    0    0    0    0 1325    0    0   13    0    0]\n",
      " [   0    0    0    1    1    0 1303    0    0    0    0]\n",
      " [   0    0    0    1   10    0    0 1308    0    0    0]\n",
      " [   0    1    0    0    0    5    0    0 1318    1    0]\n",
      " [   0   27    0    0    0    0    0    0    0 1316    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1346]]\n"
     ]
    }
   ],
   "source": [
    "### validation Data\n",
    "print(confusion_matrix(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88bf153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1294    0    0    0    0    8    0    0    1    0    0]\n",
      " [   0 1338    1    0    0    0    0    0    1   27    0]\n",
      " [   0    0 1285    0    3    0    0    0    1    1    0]\n",
      " [   0    0    0 1294    0    0    1    0    0    0    0]\n",
      " [   0    0    4    1 1284    0    0   12    0    0    0]\n",
      " [   5    0    0    0    0 1356    0    0   10    0    0]\n",
      " [   0    0    0    0    0    0 1328    0    0    0    0]\n",
      " [   0    0    0    1    8    0    0 1335    0    0    0]\n",
      " [   0    0    0    0    2    5    0    0 1287    1    0]\n",
      " [   0   17    0    0    0    0    0    0    0 1342    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1375]]\n"
     ]
    }
   ],
   "source": [
    "### Testing Data\n",
    "print(confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121310b",
   "metadata": {},
   "source": [
    "### classification report for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b4a01ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      2684\n",
      "           2       1.00      1.00      1.00      2563\n",
      "           3       1.00      1.00      1.00      2739\n",
      "           4       1.00      1.00      1.00      2688\n",
      "           5       1.00      1.00      1.00      2716\n",
      "           6       1.00      1.00      1.00      2608\n",
      "           7       1.00      1.00      1.00      2686\n",
      "           8       1.00      1.00      1.00      2656\n",
      "           9       1.00      1.00      1.00      2699\n",
      "          10       1.00      1.00      1.00      2617\n",
      "          11       1.00      1.00      1.00      2598\n",
      "\n",
      "    accuracy                           1.00     29254\n",
      "   macro avg       1.00      1.00      1.00     29254\n",
      "weighted avg       1.00      1.00      1.00     29254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the training data\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30759607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      0.99      1332\n",
      "           2       0.98      0.99      0.98      1389\n",
      "           3       1.00      1.00      1.00      1290\n",
      "           4       1.00      1.00      1.00      1336\n",
      "           5       0.99      0.99      0.99      1302\n",
      "           6       0.99      0.99      0.99      1340\n",
      "           7       1.00      1.00      1.00      1305\n",
      "           8       0.99      0.99      0.99      1319\n",
      "           9       0.99      0.99      0.99      1325\n",
      "          10       0.99      0.98      0.98      1343\n",
      "          11       1.00      1.00      1.00      1346\n",
      "\n",
      "    accuracy                           0.99     14627\n",
      "   macro avg       0.99      0.99      0.99     14627\n",
      "weighted avg       0.99      0.99      0.99     14627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the validation data\n",
    "print(classification_report(y_valid,y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "230ba798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      0.99      1303\n",
      "           2       0.99      0.98      0.98      1367\n",
      "           3       1.00      1.00      1.00      1290\n",
      "           4       1.00      1.00      1.00      1295\n",
      "           5       0.99      0.99      0.99      1301\n",
      "           6       0.99      0.99      0.99      1371\n",
      "           7       1.00      1.00      1.00      1328\n",
      "           8       0.99      0.99      0.99      1344\n",
      "           9       0.99      0.99      0.99      1295\n",
      "          10       0.98      0.99      0.98      1359\n",
      "          11       1.00      1.00      1.00      1375\n",
      "\n",
      "    accuracy                           0.99     14628\n",
      "   macro avg       0.99      0.99      0.99     14628\n",
      "weighted avg       0.99      0.99      0.99     14628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for the testing data\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872b031",
   "metadata": {},
   "source": [
    "#### ROC_auc_score for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82dbd52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The roc_auc score for the training data is 0.9999999204525996\n",
      " The roc_auc score for the validation data is 0.999881553251783\n",
      " The roc_auc score for the testing data is 0.9998939114561921\n"
     ]
    }
   ],
   "source": [
    "# roc auc score for training data\n",
    "y_train_prob = best_model_mlp.predict_proba(X_train)\n",
    "print(f\" The roc_auc score for the training data is {roc_auc_score(y_train,y_train_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the validation data\n",
    "y_valid_prob = best_model_mlp.predict_proba(X_valid)\n",
    "print(f\" The roc_auc score for the validation data is {roc_auc_score(y_valid,y_valid_prob,average='weighted',multi_class='ovr')}\")\n",
    "# roc auc score for the testing data\n",
    "y_test_prob = best_model_mlp.predict_proba(X_test)\n",
    "print(f\" The roc_auc score for the testing data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ed6fc",
   "metadata": {},
   "source": [
    "#### recall score for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1baf639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The recall score for the training data is 0.9996248970843445\n",
      " The recall score for the validation data is 0.9925126357594057\n",
      " The recall score for the testing data is 0.9925308483209835\n"
     ]
    }
   ],
   "source": [
    "# recall score for training data\n",
    "print(f\" The recall score for the training data is {recall_score(y_train,y_train_pred,average= 'macro')}\")\n",
    "# recall score for validation data\n",
    "print(f\" The recall score for the validation data is {recall_score(y_valid,y_valid_pred,average= 'macro')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the testing data is {recall_score(y_test,y_test_pred,average= 'macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce740fc4",
   "metadata": {},
   "source": [
    "### f1-score for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f829067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The f-1 score for the training data is 0.9996240106502341\n",
      " The f-1 score for the validation data is 0.9924817005460549\n",
      " The f-1 score for the testing data is 0.9924793773761309\n"
     ]
    }
   ],
   "source": [
    "# F-1 score for training data\n",
    "print(f\" The f-1 score for the training data is {f1_score(y_train,y_train_pred,average= 'weighted')}\")\n",
    "# F-1 score for validation data\n",
    "print(f\" The f-1 score for the validation data is {f1_score(y_valid,y_valid_pred,average= 'weighted')}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the testing data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2963ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
