{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d1af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c4cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_6</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_9</th>\n",
       "      <th>current_10</th>\n",
       "      <th>...</th>\n",
       "      <th>current_40</th>\n",
       "      <th>current_41</th>\n",
       "      <th>current_42</th>\n",
       "      <th>current_43</th>\n",
       "      <th>current_44</th>\n",
       "      <th>current_45</th>\n",
       "      <th>current_46</th>\n",
       "      <th>current_47</th>\n",
       "      <th>current_48</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_1     current_2  current_3  current_4     current_5  current_6  \\\n",
       "0 -3.014600e-07  8.260300e-06  -0.000012  -0.000002 -1.438600e-06  -0.000021   \n",
       "1  2.913200e-06 -5.247700e-06   0.000003  -0.000006  2.778900e-06  -0.000004   \n",
       "2 -2.951700e-06 -3.184000e-06  -0.000016  -0.000001 -1.575300e-06   0.000017   \n",
       "3 -1.322600e-06  8.820100e-06  -0.000016  -0.000005 -7.282900e-07   0.000004   \n",
       "4 -6.836600e-08  5.666300e-07  -0.000026  -0.000006 -7.940600e-07   0.000013   \n",
       "\n",
       "   current_7  current_8  current_9  current_10  ...  current_40  current_41  \\\n",
       "0   0.031718   0.031710   0.031721   -0.032963  ...    -0.63308      2.9646   \n",
       "1   0.030804   0.030810   0.030806   -0.033520  ...    -0.59314      7.6252   \n",
       "2   0.032877   0.032880   0.032896   -0.029834  ...    -0.63252      2.7784   \n",
       "3   0.029410   0.029401   0.029417   -0.030156  ...    -0.62289      6.5534   \n",
       "4   0.030119   0.030119   0.030145   -0.031393  ...    -0.63010      4.5155   \n",
       "\n",
       "   current_42  current_43  current_44  current_45  current_46  current_47  \\\n",
       "0      8.1198     -1.4961     -1.4961     -1.4961     -1.4996     -1.4996   \n",
       "1      6.1690     -1.4967     -1.4967     -1.4967     -1.5005     -1.5005   \n",
       "2      5.3017     -1.4983     -1.4983     -1.4982     -1.4985     -1.4985   \n",
       "3      6.2606     -1.4963     -1.4963     -1.4963     -1.4975     -1.4975   \n",
       "4      9.5231     -1.4958     -1.4958     -1.4958     -1.4959     -1.4959   \n",
       "\n",
       "   current_48  output  \n",
       "0     -1.4996       1  \n",
       "1     -1.5005       1  \n",
       "2     -1.4985       1  \n",
       "3     -1.4976       1  \n",
       "4     -1.4959       1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Group_9_data_cleaned.csv')\n",
    "data.head(3)\n",
    "# removing a redundant column\n",
    "df = data.drop(['Unnamed: 0'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96dde227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58509, 49)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the data \n",
    "# The data has 58509 rows \n",
    "# The data has 49 features \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec4c864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_1</th>\n",
       "      <th>current_2</th>\n",
       "      <th>current_3</th>\n",
       "      <th>current_4</th>\n",
       "      <th>current_5</th>\n",
       "      <th>current_6</th>\n",
       "      <th>current_7</th>\n",
       "      <th>current_8</th>\n",
       "      <th>current_9</th>\n",
       "      <th>current_10</th>\n",
       "      <th>...</th>\n",
       "      <th>current_40</th>\n",
       "      <th>current_41</th>\n",
       "      <th>current_42</th>\n",
       "      <th>current_43</th>\n",
       "      <th>current_44</th>\n",
       "      <th>current_45</th>\n",
       "      <th>current_46</th>\n",
       "      <th>current_47</th>\n",
       "      <th>current_48</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58509.000000</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>5.850900e+04</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "      <td>58509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.756436e-06</td>\n",
       "      <td>1.111802e-06</td>\n",
       "      <td>-9.722586e-07</td>\n",
       "      <td>1.775487e-06</td>\n",
       "      <td>-7.457535e-07</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.006349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.650427</td>\n",
       "      <td>5.730645</td>\n",
       "      <td>7.702923</td>\n",
       "      <td>-1.500891</td>\n",
       "      <td>-1.500915</td>\n",
       "      <td>-1.500809</td>\n",
       "      <td>-1.497787</td>\n",
       "      <td>-1.497814</td>\n",
       "      <td>-1.497710</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.199783e-05</td>\n",
       "      <td>1.520782e-04</td>\n",
       "      <td>7.956279e-06</td>\n",
       "      <td>3.234750e-05</td>\n",
       "      <td>1.490893e-04</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.033701</td>\n",
       "      <td>0.050735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100670</td>\n",
       "      <td>5.781169</td>\n",
       "      <td>4.347205</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>3.162305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-6.427550e-05</td>\n",
       "      <td>-2.937900e-04</td>\n",
       "      <td>-1.887580e-05</td>\n",
       "      <td>-6.547550e-05</td>\n",
       "      <td>-2.915565e-04</td>\n",
       "      <td>-0.086972</td>\n",
       "      <td>-0.087041</td>\n",
       "      <td>-0.086978</td>\n",
       "      <td>-0.111281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>-0.596830</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>-1.510950</td>\n",
       "      <td>-1.511200</td>\n",
       "      <td>-1.510700</td>\n",
       "      <td>-1.504700</td>\n",
       "      <td>-1.504550</td>\n",
       "      <td>-1.504450</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.444400e-05</td>\n",
       "      <td>-7.239600e-05</td>\n",
       "      <td>-5.417500e-06</td>\n",
       "      <td>-1.475300e-05</td>\n",
       "      <td>-7.379100e-05</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>-0.019951</td>\n",
       "      <td>-0.019925</td>\n",
       "      <td>-0.032144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715470</td>\n",
       "      <td>1.450300</td>\n",
       "      <td>4.436300</td>\n",
       "      <td>-1.503300</td>\n",
       "      <td>-1.503400</td>\n",
       "      <td>-1.503200</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499600</td>\n",
       "      <td>-1.499500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>8.804600e-07</td>\n",
       "      <td>5.137700e-07</td>\n",
       "      <td>-1.059100e-06</td>\n",
       "      <td>7.540200e-07</td>\n",
       "      <td>-1.659300e-07</td>\n",
       "      <td>0.013226</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>-0.015566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661710</td>\n",
       "      <td>3.301300</td>\n",
       "      <td>6.479100</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.500300</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498100</td>\n",
       "      <td>-1.498000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.877700e-05</td>\n",
       "      <td>7.520000e-05</td>\n",
       "      <td>3.554700e-06</td>\n",
       "      <td>1.906200e-05</td>\n",
       "      <td>7.138600e-05</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573980</td>\n",
       "      <td>8.288500</td>\n",
       "      <td>9.857500</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.498200</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>-1.496300</td>\n",
       "      <td>-1.496200</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>6.860850e-05</td>\n",
       "      <td>2.965940e-04</td>\n",
       "      <td>1.701300e-05</td>\n",
       "      <td>6.978450e-05</td>\n",
       "      <td>2.891515e-04</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.069130</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>0.099751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361745</td>\n",
       "      <td>18.545800</td>\n",
       "      <td>17.989300</td>\n",
       "      <td>-1.490550</td>\n",
       "      <td>-1.490400</td>\n",
       "      <td>-1.490700</td>\n",
       "      <td>-1.491100</td>\n",
       "      <td>-1.491350</td>\n",
       "      <td>-1.491250</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          current_1     current_2     current_3     current_4     current_5  \\\n",
       "count  58509.000000  5.850900e+04  5.850900e+04  5.850900e+04  5.850900e+04   \n",
       "mean      -0.000003  1.756436e-06  1.111802e-06 -9.722586e-07  1.775487e-06   \n",
       "std        0.000008  3.199783e-05  1.520782e-04  7.956279e-06  3.234750e-05   \n",
       "min       -0.000021 -6.427550e-05 -2.937900e-04 -1.887580e-05 -6.547550e-05   \n",
       "25%       -0.000007 -1.444400e-05 -7.239600e-05 -5.417500e-06 -1.475300e-05   \n",
       "50%       -0.000003  8.804600e-07  5.137700e-07 -1.059100e-06  7.540200e-07   \n",
       "75%        0.000002  1.877700e-05  7.520000e-05  3.554700e-06  1.906200e-05   \n",
       "max        0.000015  6.860850e-05  2.965940e-04  1.701300e-05  6.978450e-05   \n",
       "\n",
       "          current_6     current_7     current_8     current_9    current_10  \\\n",
       "count  5.850900e+04  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean  -7.457535e-07      0.002854      0.002849      0.002849     -0.006349   \n",
       "std    1.490893e-04      0.033692      0.033700      0.033701      0.050735   \n",
       "min   -2.915565e-04     -0.086972     -0.087041     -0.086978     -0.111281   \n",
       "25%   -7.379100e-05     -0.019927     -0.019951     -0.019925     -0.032144   \n",
       "50%   -1.659300e-07      0.013226      0.013230      0.013247     -0.015566   \n",
       "75%    7.138600e-05      0.024770      0.024776      0.024777      0.020614   \n",
       "max    2.891515e-04      0.069125      0.069130      0.069131      0.099751   \n",
       "\n",
       "       ...    current_40    current_41    current_42    current_43  \\\n",
       "count  ...  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean   ...     -0.650427      5.730645      7.702923     -1.500891   \n",
       "std    ...      0.100670      5.781169      4.347205      0.003629   \n",
       "min    ...     -0.902350     -0.596830      0.320660     -1.510950   \n",
       "25%    ...     -0.715470      1.450300      4.436300     -1.503300   \n",
       "50%    ...     -0.661710      3.301300      6.479100     -1.500300   \n",
       "75%    ...     -0.573980      8.288500      9.857500     -1.498200   \n",
       "max    ...     -0.361745     18.545800     17.989300     -1.490550   \n",
       "\n",
       "         current_44    current_45    current_46    current_47    current_48  \\\n",
       "count  58509.000000  58509.000000  58509.000000  58509.000000  58509.000000   \n",
       "mean      -1.500915     -1.500809     -1.497787     -1.497814     -1.497710   \n",
       "std        0.003640      0.003600      0.003002      0.002984      0.002988   \n",
       "min       -1.511200     -1.510700     -1.504700     -1.504550     -1.504450   \n",
       "25%       -1.503400     -1.503200     -1.499600     -1.499600     -1.499500   \n",
       "50%       -1.500300     -1.500300     -1.498100     -1.498100     -1.498000   \n",
       "75%       -1.498200     -1.498200     -1.496200     -1.496300     -1.496200   \n",
       "max       -1.490400     -1.490700     -1.491100     -1.491350     -1.491250   \n",
       "\n",
       "             output  \n",
       "count  58509.000000  \n",
       "mean       6.000000  \n",
       "std        3.162305  \n",
       "min        1.000000  \n",
       "25%        3.000000  \n",
       "50%        6.000000  \n",
       "75%        9.000000  \n",
       "max       11.000000  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of the data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3dd28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 11 different classes in the output data \n",
    "# which are from 1 to 11 classes \n",
    "df['output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7164bb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5319\n",
       "2     5319\n",
       "3     5319\n",
       "4     5319\n",
       "5     5319\n",
       "6     5319\n",
       "7     5319\n",
       "8     5319\n",
       "9     5319\n",
       "10    5319\n",
       "11    5319\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the number of each output class labels \n",
    "# It is a blanced multi class dataset with each class is having equal number of output labels \n",
    "df['output'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbeca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing input and output labels\n",
    "X = df.drop(['output'],axis=1)\n",
    "y = df['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e382d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5730026  0.54585804 0.47811763 ... 0.375      0.375      0.36742424]\n",
      " [0.66228185 0.44420547 0.50328617 ... 0.30882353 0.30681818 0.29924242]\n",
      " [0.49939872 0.45973556 0.47065977 ... 0.45588235 0.45833333 0.45075758]\n",
      " ...\n",
      " [0.41869175 0.62362286 0.32534757 ... 1.         1.         1.        ]\n",
      " [0.45803432 0.73932528 0.         ... 0.84558824 0.85984848 0.85984848]\n",
      " [0.33549635 0.87696412 0.62036912 ... 0.75       0.75378788 0.76893939]]\n"
     ]
    }
   ],
   "source": [
    "# importing Min Max scalar for the data transformation\n",
    "# Scaling is very important in the case of linear regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "print(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac060669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset into train,test and validation sets\n",
    "X_train, X_rem, y_train, y_rem  = train_test_split(scaled_X, y, train_size = 0.5, random_state = 100)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size = 0.5, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d728986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The input training  data shape is (29254, 48)\n",
      " The  output training data shape is (29254,)\n",
      " The input validation  data shape is (14627, 48)\n",
      " The  output validation data shape is (14627,)\n",
      " The input testing  data shape is (14627, 48)\n",
      " The  output testing data shape is (14627,)\n"
     ]
    }
   ],
   "source": [
    "# The shape of training dataset\n",
    "print(f\" The input training  data shape is {X_train.shape}\")\n",
    "print(f\" The  output training data shape is {y_train.shape}\")\n",
    "print(f\" The input validation  data shape is {X_valid.shape}\")\n",
    "print(f\" The  output validation data shape is {y_valid.shape}\")\n",
    "# The shape of the test dataset \n",
    "print(f\" The input testing  data shape is {X_valid.shape}\")\n",
    "print(f\" The  output testing data shape is {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b8046",
   "metadata": {},
   "source": [
    "## Ensemble models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fec427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05098108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m1 = RandomForestClassifier()\n",
    "m2 = AdaBoostClassifier()\n",
    "m3 = GradientBoostingClassifier()\n",
    "m4 = BaggingClassifier()\n",
    "m5 = RandomForestClassifier(n_estimators= 10, max_features= 'sqrt', max_depth= 3,bootstrap=True)\n",
    "m6 = AdaBoostClassifier(n_estimators= 10)\n",
    "m7 = DecisionTreeClassifier()\n",
    "m8 = DecisionTreeClassifier(max_depth=5)\n",
    "m9 = DecisionTreeClassifier(splitter='random', min_samples_split= 7, min_samples_leaf= 1, \n",
    "                                  max_depth= 2)\n",
    "m10 = AdaBoostClassifier(n_estimators=40,random_state=0)\n",
    "m11 = RandomForestClassifier(n_estimators= 100, max_features= 'sqrt', max_depth= 4,bootstrap=False)\n",
    "m12 = AdaBoostClassifier(n_estimators = 50,random_state=0)\n",
    "m13 = LogisticRegression()\n",
    "m14 = KNeighborsClassifier(n_neighbors=8)\n",
    "m15 = KNeighborsClassifier(n_neighbors=5)\n",
    "m16 = svm.SVC(kernel ='linear',C=100,gamma=1,probability=True)\n",
    "m17 = svm.SVC(C= 100, gamma= 0.1, kernel= 'rbf',probability=True)\n",
    "m18 = RandomForestClassifier(n_estimators= 5, max_features= 'sqrt', max_depth= 4,bootstrap=False)\n",
    "m19 = GaussianNB()\n",
    "m20 = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20c1e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Classifier\n",
    "\n",
    "en_cls = VotingClassifier(estimators=[('r_1', m1),('ab_1', m2),('gb', m3),('bg', m4),('random_2',m5),('ada_2',m6),('decision_t_1',m7),('deci_t',m8),\n",
    "    ('decisiontree',m9),('adaboost',m10),('randomforest',m11),('ada_classifier',m12),('lg',m13),('knn_1',m14),('Kneigh',m15),('svm_1',m16),('svm_classifier',m17),\n",
    "                                     ('random_classifier',m18),('gb_2',m19),('rdg',m20)],voting=\"soft\")\n",
    "en_cls = en_cls.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb5b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9c74312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The training data accuracy for the best model is 0.99822246530389\n",
      " The validation data accuracy for the best model is 0.9901551924523142\n",
      " The testing data accuracy for the best model is 0.9907027618266339\n"
     ]
    }
   ],
   "source": [
    "# accuracy for train and validation sets\n",
    "y_train_pred = en_cls.predict(X_train)\n",
    "y_valid_pred = en_cls.predict(X_valid)\n",
    "y_test_pred  = en_cls.predict(X_test)\n",
    "print(f\" The training data accuracy for the best model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The validation data accuracy for the best model is {accuracy_score(y_valid,y_valid_pred)}\")\n",
    "print(f\" The testing data accuracy for the best model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93e68c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1299    0    0    0    0    4    0    0    0    0    0]\n",
      " [   0 1345    0    0    0    0    0    0    0   21    1]\n",
      " [   0    0 1284    0    5    0    0    0    1    0    0]\n",
      " [   0    0    2 1292    1    0    0    0    0    0    0]\n",
      " [   0    0    3    2 1277    0    0   19    0    0    0]\n",
      " [   5    0    1    0    0 1363    0    0    2    0    0]\n",
      " [   0    0    0    0    0    0 1328    0    0    0    0]\n",
      " [   0    0    0    2    9    0    0 1333    0    0    0]\n",
      " [   0    1    0    0    0    6    0    1 1285    2    0]\n",
      " [   0   48    0    0    0    0    0    0    0 1311    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0 1375]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for the test data\n",
    "print(confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b41fd5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1303\n",
      "           2       0.96      0.98      0.97      1367\n",
      "           3       1.00      1.00      1.00      1290\n",
      "           4       1.00      1.00      1.00      1295\n",
      "           5       0.99      0.98      0.98      1301\n",
      "           6       0.99      0.99      0.99      1371\n",
      "           7       1.00      1.00      1.00      1328\n",
      "           8       0.99      0.99      0.99      1344\n",
      "           9       1.00      0.99      0.99      1295\n",
      "          10       0.98      0.96      0.97      1359\n",
      "          11       1.00      1.00      1.00      1375\n",
      "\n",
      "    accuracy                           0.99     14628\n",
      "   macro avg       0.99      0.99      0.99     14628\n",
      "weighted avg       0.99      0.99      0.99     14628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for test data\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c113afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The f-1 score for the testing data is 0.9907023409847315\n",
      " The recall score for the testing data is 0.9907599668650309\n",
      " The roc_auc score for the testing data is 0.9999098191200902\n"
     ]
    }
   ],
   "source": [
    "# roc auc score, f1 score and recall score for the model using test data\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the testing data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the testing data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "y_test_prob = en_cls.predict_proba(X_test)\n",
    "print(f\" The roc_auc score for the testing data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca12c6",
   "metadata": {},
   "source": [
    "### comparing with the other models from part -2  for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bafdfc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Load the trained Best Linear Regression model\n",
    "sgd=pickle.load(open('best_sgd.sav', 'rb'))\n",
    "# load Logistic Regression model\n",
    "log = pickle.load(open('best_log.sav','rb'))\n",
    "#load the best knn model\n",
    "knn = pickle.load(open('knn_class.sav', 'rb'))\n",
    "#load Random fores model\n",
    "rf = pickle.load(open('RF_class.sav', 'rb'))\n",
    "#load Decision Trees model\n",
    "dt = pickle.load(open('Tree_class.sav','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c4f2f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy sgd model is 0.7110138784439735\n",
      " The test data accuracy sgd model is 0.717391304347826\n",
      " The f-1 score for the test data is 0.707233840421796\n",
      " The recall score for the test  data is 0.7134731912978303\n",
      " The roc_auc score for the test  data is 0.9678055964386405\n"
     ]
    }
   ],
   "source": [
    "# Test results for stochastic gradient classifier\n",
    "sgd.fit(X_train,y_train)\n",
    "y_test_pred = sgd.predict(X_test)\n",
    "y_test_proba = sgd.predict_proba(X_test)\n",
    "y_train_pred = sgd.predict(X_train)\n",
    "print(f\" The train data accuracy sgd model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy sgd model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_proba,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "210e770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy logistic model is 0.9095850140151774\n",
      " The test data accuracy logistic model is 0.9079846869018321\n",
      " The f-1 score for the test data is 0.9074211119324297\n",
      " The recall score for the test  data is 0.9080651377504487\n",
      " The roc_auc score for the test  data is 0.9944914153014618\n"
     ]
    }
   ],
   "source": [
    "# Test results for logistic regression\n",
    "log.fit(X_train,y_train)\n",
    "y_test_pred = log.predict(X_test)\n",
    "y_test_prob = log.predict_proba(X_test)\n",
    "y_train_pred = log.predict(X_train)\n",
    "print(f\" The train data accuracy logistic model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy logistic model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd5cd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy knn model is 1.0\n",
      " The test data accuracy knn model is 0.977167076838939\n",
      " The f-1 score for the test data is 0.9771679005724067\n",
      " The recall score for the test  data is 0.9773191105658197\n",
      " The roc_auc score for the test  data is 0.9994541676847498\n"
     ]
    }
   ],
   "source": [
    "# Test results for KNN classification\n",
    "knn.fit(X_train,y_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "y_test_prob = knn.predict_proba(X_test)\n",
    "y_train_pred = knn.predict(X_train)\n",
    "print(f\" The train data accuracy knn model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy knn model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6721682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy trees model is 0.9800369180283038\n",
      " The test data accuracy decision tree model is 0.9695105277549905\n",
      " The f-1 score for the test data is 0.9696162578144502\n",
      " The recall score for the test  data is 0.9693421187900643\n",
      " The roc_auc score for the test  data is 0.9947688638135779\n"
     ]
    }
   ],
   "source": [
    "# Test results for decision tree classification\n",
    "dt.fit(X_train,y_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "y_test_prob = dt.predict_proba(X_test)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "print(f\" The train data accuracy trees model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy decision tree model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92eab960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy random forest model is 0.99347097832775\n",
      " The test data accuracy random forest model is 0.9902242275088871\n",
      " The f-1 score for the test data is 0.9902190906089697\n",
      " The recall score for the test  data is 0.9901383172987909\n",
      " The roc_auc score for the test  data is 0.9999107455760874\n"
     ]
    }
   ],
   "source": [
    "# Test results for random forest classification\n",
    "rf.fit(X_train,y_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_prob = rf.predict_proba(X_test)\n",
    "y_train_pred = rf.predict(X_train)\n",
    "print(f\" The train data accuracy random forest model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy random forest model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3ae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ca231a",
   "metadata": {},
   "source": [
    "### comparing models from part-3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f55c9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best svm linear model\n",
    "svm_linear=pickle.load(open('svm_linear.sav', 'rb'))\n",
    "# load the best non linear svm model\n",
    "svm_nonlinear = pickle.load(open('svm_nonlinear.sav','rb'))\n",
    "#load the best deep learning model\n",
    "mlp = pickle.load(open('mlp.sav', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "008df7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy svm linear model is 0.9402474875230737\n",
      " The test data accuracy svm linear model is 0.9365600218758545\n",
      " The f-1 score for the test data is 0.9363181793454444\n",
      " The recall score for the test  data is 0.9367212302821362\n",
      " The roc_auc score for the test  data is 0.9967427231962683\n"
     ]
    }
   ],
   "source": [
    "# Test results for svm linear classification\n",
    "svm_linear.fit(X_train,y_train)\n",
    "y_test_pred = svm_linear.predict(X_test)\n",
    "y_test_prob = svm_linear.predict_proba(X_test)\n",
    "y_train_pred = svm_linear.predict(X_train)\n",
    "print(f\" The train data accuracy svm linear model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy svm linear model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f06ef262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy svm non linear model is 0.9960347302932933\n",
      " The test data accuracy svm non linear model is 0.9849603500136724\n",
      " The f-1 score for the test data is 0.9849551502008304\n",
      " The recall score for the test  data is 0.9851186874234373\n",
      " The roc_auc score for the test  data is 0.9997320141256982\n"
     ]
    }
   ],
   "source": [
    "# Test results for svm Non linear classification\n",
    "svm_nonlinear.fit(X_train,y_train)\n",
    "y_test_pred = svm_nonlinear.predict(X_test)\n",
    "y_test_prob = svm_nonlinear.predict_proba(X_test)\n",
    "y_train_pred = svm_nonlinear.predict(X_train)\n",
    "print(f\" The train data accuracy svm non linear model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy svm non linear model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45f7c4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The train data accuracy mlp model is 0.9994530662473508\n",
      " The test data accuracy mlp model is 0.9928903472791906\n",
      " The f-1 score for the test data is 0.992893330008273\n",
      " The recall score for the test  data is 0.9929074037979327\n",
      " The roc_auc score for the test  data is 0.999886270966743\n"
     ]
    }
   ],
   "source": [
    "# Test results for deep learning mlp classification\n",
    "mlp.fit(X_train,y_train)\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "y_test_prob = mlp.predict_proba(X_test)\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "print(f\" The train data accuracy mlp model is {accuracy_score(y_train,y_train_pred)}\")\n",
    "print(f\" The test data accuracy mlp model is {accuracy_score(y_test,y_test_pred)}\")\n",
    "# F-1 score for test data\n",
    "print(f\" The f-1 score for the test data is {f1_score(y_test,y_test_pred,average= 'weighted')}\")\n",
    "# recall score for test data\n",
    "print(f\" The recall score for the test  data is {recall_score(y_test,y_test_pred,average= 'macro')}\")\n",
    "print(f\" The roc_auc score for the test  data is {roc_auc_score(y_test,y_test_prob,average='weighted',multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19671506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By the comparison of all these models with the ensemble model , all the remaining models having much difference between-\n",
    "# the training and testing accuracy , while ensemble model has little difference between the training and testing accuracy.\n",
    "# The ensemble model has lower variance compared to other models.\n",
    "# The ensemble model has slightly higher bias compare with deep learning and random forest models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
